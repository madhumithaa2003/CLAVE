{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hdVTf0teISQ"
      },
      "source": [
        "# Inference with CLAVE\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/davidaf3/CLAVE/blob/master/src/run_clave.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "\n",
        "This notebook shows how you can run inference on CLAVE and creates a Gradio UI that lets you experiment with the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjolsx19eIST"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Install the necessary dependencies. This only install the packages that are not available in Colab. If you are not using Colab, you might need to install `torch`, `requests`, and `tqdm`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "iyYRjuW5eIST",
        "outputId": "e50632df-5036-4445-d1e7-b33a36f268ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rarfile in /usr/local/lib/python3.11/dist-packages (4.2)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.22.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.8.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.29.3)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.6)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.2)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.1)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (14.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "%pip install rarfile gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0ceESq7eISU"
      },
      "source": [
        "Clone CLAVE's repo and move into it. If you are running this notebook locally and have already clone the repo, this step is not necessary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWEqE6G7eISV"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/davidaf3/CLAVE.git\n",
        "%cd CLAVE/src"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALLR3tEreISV"
      },
      "source": [
        "## Download the model weights\n",
        "First, download the model weights and SentencePiece parameter from the provided URLs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ER6FBAZ3eISV",
        "outputId": "63a3470f-8f22-4cce-e631-37160b0eca6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 277M/277M [00:24<00:00, 11.4MB/s]\n",
            "100%|██████████| 1.03M/1.03M [00:00<00:00, 1.18MB/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "import requests\n",
        "\n",
        "\n",
        "res = requests.get(\n",
        "    \"https://www.reflection.uniovi.es/bigcode/download/2024/CLAVE/model.rar\",\n",
        "    stream=True,\n",
        ")\n",
        "\n",
        "with tqdm(\n",
        "    total=int(res.headers.get(\"content-length\", 0)), unit=\"B\", unit_scale=True\n",
        ") as progress_bar:\n",
        "    with open(\"model.rar\", \"wb\") as f:\n",
        "        for data in res.iter_content(1024):\n",
        "            progress_bar.update(len(data))\n",
        "            f.write(data)\n",
        "\n",
        "res = requests.get(\n",
        "    \"https://www.reflection.uniovi.es/bigcode/download/2024/CLAVE/tokenizer_data.zip\",\n",
        "    stream=True,\n",
        ")\n",
        "\n",
        "with tqdm(\n",
        "    total=int(res.headers.get(\"content-length\", 0)), unit=\"B\", unit_scale=True\n",
        ") as progress_bar:\n",
        "    with open(\"tokenizer_data.zip\", \"wb\") as f:\n",
        "        for data in res.iter_content(1024):\n",
        "            progress_bar.update(len(data))\n",
        "            f.write(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmZvBQJQeISV"
      },
      "source": [
        "Extract the downloaded `model.rar` and `tokenizer_data.zip` files:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "v7SfciAmeISW"
      },
      "outputs": [],
      "source": [
        "import rarfile\n",
        "import zipfile\n",
        "\n",
        "\n",
        "with rarfile.RarFile(\"model.rar\") as f:\n",
        "    f.extractall(path=\".\")\n",
        "\n",
        "with zipfile.ZipFile(\"tokenizer_data.zip\") as f:\n",
        "    f.extractall(path=\".\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4rZ80TDeISW"
      },
      "source": [
        "## Load the weights\n",
        "Create a new model (`FineTunedModel` class) and load the weights from the extracted file (`CLAVE.pt`):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "JvNmODX1eISW",
        "outputId": "45f8809e-e759-4f0a-fa23-ab42acbead4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FineTunedModel(\n",
              "  (encoder): Encoder(\n",
              "    (transformer_encoder): TransformerEncoder(\n",
              "      (layers): ModuleList(\n",
              "        (0-5): 6 x TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.1, inplace=False)\n",
              "          (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (embedding): Embedding(16000, 512)\n",
              "    (pos_embedding): Embedding(2048, 512)\n",
              "    (embedding_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    (embedding_dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "  (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "  (activation): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "import torch\n",
        "from model import FineTunedModel\n",
        "from tokenizer import SpTokenizer\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = FineTunedModel(\n",
        "    SpTokenizer.get_vocab_size(), 512, 512, 8, 2048, 6, use_layer_norm=True\n",
        ").to(device)\n",
        "model_checkpoint = torch.load(\"CLAVE.pt\", map_location=device)\n",
        "weights = {\n",
        "    k[10:] if k.startswith(\"_orig_mod\") else k: v\n",
        "    for k, v in model_checkpoint[\"model_state_dict\"].items()\n",
        "}\n",
        "model.load_state_dict(weights)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvyjlW_QeISX"
      },
      "source": [
        "## Start the UI\n",
        "Start the Gradio UI configured to run the `verify_authorship` function. This function tokenizes the inputs, processes the tokens with CLAVE to obtain an embedding for each input, and computes the distance between the embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICE939ljeISX"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import torch.nn.functional as F\n",
        "from utils import pad_and_split_tokens\n",
        "\n",
        "\n",
        "tokenizer = SpTokenizer()\n",
        "threshold = 0.1050\n",
        "\n",
        "\n",
        "def verify_authorship(source_code_1, source_code_2):\n",
        "    with torch.inference_mode():\n",
        "        tokens_1 = pad_and_split_tokens(tokenizer.tokenizes(source_code_1))[0]\n",
        "        tokens_2 = pad_and_split_tokens(tokenizer.tokenizes(source_code_2))[0]\n",
        "        embedding_1 = model(torch.tensor([tokens_1], device=device))\n",
        "        embedding_2 = model(torch.tensor([tokens_2], device=device))\n",
        "        distance = (1 - F.cosine_similarity(embedding_1, embedding_2)).item()\n",
        "        return [\n",
        "            distance,\n",
        "            \"Yes\" if distance <= threshold else \"No\",\n",
        "        ]\n",
        "\n",
        "\n",
        "ui = gr.Interface(\n",
        "    fn=verify_authorship,\n",
        "    inputs=[\n",
        "        gr.Code(language=\"python\", label=\"Source code 1\"),\n",
        "        gr.Code(language=\"python\", label=\"Source code 2\"),\n",
        "    ],\n",
        "    outputs=[gr.Number(label=\"Distance\"), gr.Text(label=\"Same author?\")],\n",
        "    allow_flagging=\"never\",\n",
        ")\n",
        "ui.launch()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "odmb_wM6emWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import shap\n",
        "import sentencepiece as spm\n",
        "from utils import pad_and_split_tokens\n",
        "\n",
        "# Load SentencePiece tokenizer\n",
        "tokenizer_path = \"/content/CLAVE/src/tokenizer_data/tokenizer.model\"\n",
        "sp = spm.SentencePieceProcessor(model_file=tokenizer_path)\n",
        "\n",
        "# Custom wrapper for SHAP\n",
        "class CustomTokenizerWrapper:\n",
        "    def __init__(self, sp):\n",
        "        self.sp = sp\n",
        "\n",
        "    def encode(self, text):\n",
        "        tokens = self.sp.encode(text, out_type=str)\n",
        "        return {\"input_ids\": tokens}\n",
        "\n",
        "    def decode(self, tokens):\n",
        "        return self.sp.decode(tokens)\n",
        "\n",
        "wrapped_tokenizer = CustomTokenizerWrapper(sp)\n",
        "masker = shap.maskers.Text(wrapped_tokenizer.encode)\n",
        "\n",
        "# Load trained model\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = torch.load(\"CLAVE.pt\", map_location=device)\n",
        "model.eval()\n",
        "\n",
        "# SHAP explainer\n",
        "explainer = shap.Explainer(model, masker)\n",
        "\n",
        "# Function to highlight code\n",
        "def highlight_code(code, shap_values):\n",
        "    tokens = sp.encode(code, out_type=str)\n",
        "    highlighted_code = \"\"\n",
        "\n",
        "    for i, token in enumerate(tokens):\n",
        "        color = \"red\" if shap_values[i] > 0 else \"green\"  # Red = Similarity, Green = Difference\n",
        "        highlighted_code += f'<span style=\"color: {color};\">{token}</span> '\n",
        "\n",
        "    return f'<pre>{highlighted_code}</pre>'\n",
        "\n",
        "# Function for authorship verification\n",
        "def verify_authorship(source_code_1, source_code_2):\n",
        "    with torch.inference_mode():\n",
        "        tokens_1 = pad_and_split_tokens(sp.encode(source_code_1, out_type=int))[0]\n",
        "        tokens_2 = pad_and_split_tokens(sp.encode(source_code_2, out_type=int))[0]\n",
        "\n",
        "        embedding_1 = model(torch.tensor([tokens_1], device=device))\n",
        "        embedding_2 = model(torch.tensor([tokens_2], device=device))\n",
        "\n",
        "        distance = (1 - F.cosine_similarity(embedding_1, embedding_2)).item()\n",
        "\n",
        "        # SHAP explanation\n",
        "        shap_values_1 = explainer([tokens_1])\n",
        "        shap_values_2 = explainer([tokens_2])\n",
        "\n",
        "        highlighted_code_1 = highlight_code(source_code_1, shap_values_1.values[0])\n",
        "        highlighted_code_2 = highlight_code(source_code_2, shap_values_2.values[0])\n",
        "\n",
        "        return distance, \"Yes\" if distance <= 0.1050 else \"No\", highlighted_code_1, highlighted_code_2\n",
        "\n",
        "# Gradio UI\n",
        "ui = gr.Interface(\n",
        "    fn=verify_authorship,\n",
        "    inputs=[\n",
        "        gr.Code(language=\"python\", label=\"Source code 1\"),\n",
        "        gr.Code(language=\"python\", label=\"Source code 2\"),\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Number(label=\"Distance\"),\n",
        "        gr.Text(label=\"Same author?\"),\n",
        "        gr.HTML(label=\"Highlighted Code 1\"),\n",
        "        gr.HTML(label=\"Highlighted Code 2\"),\n",
        "    ],\n",
        "    allow_flagging=\"never\",\n",
        ")\n",
        "ui.launch()"
      ],
      "metadata": {
        "id": "bKIaLAMWemLH",
        "outputId": "0299fd83-bc16-4fd9-d970-8a6860a46fd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'dict' object has no attribute 'eval'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-af2e03f464de>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CLAVE.pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# SHAP explainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'eval'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2ePNbvB-essi"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "tfm-torch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}